<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>分布式平台 on Davidham的博客</title><link>https://davidham3.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/</link><description>Recent content in 分布式平台 on Davidham的博客</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 13 Feb 2020 00:12:07 +0000</lastBuildDate><atom:link href="https://davidham3.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/index.xml" rel="self" type="application/rss+xml"/><item><title>记一次pyspark性能提升，np.frombuffer的使用</title><link>https://davidham3.github.io/blog/p/%E8%AE%B0%E4%B8%80%E6%AC%A1pyspark%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87np.frombuffer%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Thu, 13 Feb 2020 00:12:07 +0000</pubDate><guid>https://davidham3.github.io/blog/p/%E8%AE%B0%E4%B8%80%E6%AC%A1pyspark%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87np.frombuffer%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>&lt;p>之前项目中有个任务是读取一堆二进制文件，对二进制文件进行解析，然后存到HBase。由于有 .mat 文件，整个 spark 都用 pyspark 写来着，也没用 scala。最近天天都在写文档啥的，还得写毕业论文，觉得太没劲了就研究了一下优化的问题，顺便更新下博客，好久没更新了。&lt;/p>
&lt;p>原来的数据格式很简单，就是一堆 float 类型的数字，转成了二进制的形式，每 4 个字节一个数，连续地写到了文件里面。因为文件很多，而且要存到 HBase，就选择用 Spark 来处理。每个文件差不多 300M，里面的数字很多，最后的目标是提取成文件内数据为矩阵的形式。每个文件里面有 $K \times M \times N$ 个浮点型数字。要提取成 $K$ 个 $M \times N$ 的矩阵。&lt;/p>
&lt;p>假设 $K = 500$，$M = 5000$, $N = 30$，首先写一个数据生成器出来：&lt;/p>
&lt;p>data_generator.py&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># -*- coding:utf-8 -*-&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">K&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">500&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">M&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">5000&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">N&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">30&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">K&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">M&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">N&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uniform&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">,))&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tofile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;test.data&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>原来不知道有这个 np.tofile，今天才知道的。。。速度很快，准确的说是太快了。。。&lt;/p>
&lt;p>数据使用 sparkContext 的 binaryFiles 就可以读到内存中，以 bytes 的形式存储。&lt;/p>
&lt;p>原来我提取 $K$ 个矩阵的方法是：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">K&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">500&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">M&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">5000&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">N&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">30&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">UNIT&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">M&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">N&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">UNIT_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">UNIT&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">4&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">record_time&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">wrapper&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">time&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">wrapper&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">struct&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unpack&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{}&lt;/span>&lt;span class="s1">f&amp;#39;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">UNIT&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>直接用 struct.unpack $K$ 次，而且每次都用 np.array 构造出新的 array。但是不得不说，因为 python 底层是 C 写的，这个 struct.unpack 很快，完成上面的解析只需要 10s。当时想着 python 解析这个的速度肯定没有 scala 快，写成这样应该就差不多了。但是最近我都没怎么写程序，就想研究研究能不能优化。&lt;/p>
&lt;h2 id="优化方案1使用-c-重写这部分">优化方案1：使用 C++ 重写这部分
&lt;/h2>&lt;p>我当时觉得，使用 C++ 完成 bytes 到 np.ndarray 的转换应该快一点，然后就写了一个：&lt;/p>
&lt;p>tools.cpp&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;iostream&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;fstream&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;string&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;ctime&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;cstring&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;time.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;Eigen/Dense&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&amp;lt;pybind11/eigen.h&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;pybind11/pybind11.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">using&lt;/span> &lt;span class="k">namespace&lt;/span> &lt;span class="n">std&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">using&lt;/span> &lt;span class="n">Eigen&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">MatrixXd&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">MatrixXd&lt;/span> &lt;span class="nf">extract_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">long&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">k_idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">char&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">stream&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">float&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MatrixXd&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">long&lt;/span> &lt;span class="n">offset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">k_idx&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">r&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">r&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">M&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">r&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">memcpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">stream&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">offset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">m&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">r&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">offset&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">PYBIND11_MODULE&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tools&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">def&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;extract_matrix&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">extract_matrix&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pybind11&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">return_value_policy&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">reference&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>实际上是利用 pybind11 实现了一个 C++ 函数，使用下面的命令编译：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="n">c&lt;/span>&lt;span class="o">++&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">O3&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">Wall&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">shared&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">std&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="mi">11&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">fPIC&lt;/span> &lt;span class="err">`&lt;/span>&lt;span class="n">python3&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">m&lt;/span> &lt;span class="n">pybind11&lt;/span> &lt;span class="o">--&lt;/span>&lt;span class="n">includes&lt;/span>&lt;span class="err">`&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">I&lt;/span> &lt;span class="o">/&lt;/span>&lt;span class="n">mnt&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">Users&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">chaosong&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">Downloads&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">eigen&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mf">3.3&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="mi">7&lt;/span> &lt;span class="n">tools&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cpp&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">o&lt;/span> &lt;span class="n">tools&lt;/span>&lt;span class="err">`&lt;/span>&lt;span class="n">python3&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">config&lt;/span> &lt;span class="o">--&lt;/span>&lt;span class="n">extension&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">suffix&lt;/span>&lt;span class="err">`&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后 python 就可以导入了&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">tools&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tools&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extract_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">content&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>结果这玩意出奇的慢。。。用这个 method2 处理那个文件要 254s。比原来的方法慢了 25 倍。&lt;/p>
&lt;h2 id="优化方案2使用-npfrombuffer">优化方案2：使用 np.frombuffer
&lt;/h2>&lt;p>我去看了看 numpy 的文档，结果发现了这个函数，这个函数可以直接读 bytes，都不需要用 struct 解析了。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frombuffer&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">UNIT&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这里我故意写成切片的形式，为了和优化方案3的速度做对比。但即便是循环 K 次，将原始数据用切片进行了复制，这个方法的时间都能达到 0.03s，比我那个失败的方案 1 快了 8467 倍，比原方案快了 333 倍。&lt;/p>
&lt;h2 id="优化方案3使用-npfrombuffer">优化方案3：使用 np.frombuffer
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method4&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frombuffer&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">UNIT&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">offset&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个能跑到 0.0007s。比方案 1 快 36 万倍，比原方案快 14285 倍，比方案 2 快 42 倍。&lt;/p>
&lt;p>结论：&lt;/p>
&lt;ol>
&lt;li>我的那个方案 1 太差劲了，肯定是我不会写才导致的。。。看看以后啥时候有时间研究一下&lt;/li>
&lt;li>np.frombuffer，太强了。。。&lt;/li>
&lt;li>多看 API。&lt;/li>
&lt;li>python 的 struct 其实挺快的，但是基于 C/C++ 的 numpy 更快，无敌快。&lt;/li>
&lt;/ol>
&lt;p>附上完整代码：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># -*- coding:utf-8 -*-&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">struct&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">tools&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;test.data&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;rb&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">K&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">500&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">M&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">5000&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">N&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">30&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">UNIT&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">M&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">N&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">UNIT_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">UNIT&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">4&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">record_time&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">wrapper&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">time&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">wrapper&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">struct&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unpack&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{}&lt;/span>&lt;span class="s1">f&amp;#39;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">UNIT&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tools&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extract_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">content&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frombuffer&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">UNIT&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@record_time&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">method4&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">K&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frombuffer&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">content&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">UNIT&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">offset&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">UNIT_&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">M&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">N&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;__main__&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">method1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">method2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">method3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">method4&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>接下来需要验证的是，我们的 pyspark 程序比原来快了多少，这个明天再验证吧。&lt;/p></description></item><item><title>pyspark读写HBase</title><link>https://davidham3.github.io/blog/p/pyspark%E8%AF%BB%E5%86%99hbase/</link><pubDate>Wed, 10 Apr 2019 17:26:30 +0000</pubDate><guid>https://davidham3.github.io/blog/p/pyspark%E8%AF%BB%E5%86%99hbase/</guid><description>&lt;p>应甲方需求，写一个 pyspark 读写 HBase 的教程。主要包含了基本读写方法和自定义 Converter 的方法。&lt;/p>
&lt;h1 id="pyspark-读取-hbase">pyspark 读取 HBase
&lt;/h1>&lt;p>以下内容的环境：python 3.5，spark 1.6&lt;/p>
&lt;p>pyspark 读取 HBase 需要借助 Java 的类完成读写。&lt;/p>
&lt;p>首先需要明确的是，HBase 中存储的是 &lt;code>byte[]&lt;/code>，也就是说，不管是什么样的数据，都需要先转换为 &lt;code>byte[]&lt;/code> 后，才能存入 HBase。&lt;/p>
&lt;h2 id="基本方法">基本方法
&lt;/h2>&lt;p>pyspark 读取 HBase 需要使用 &lt;code>SparkContext&lt;/code> 的 &lt;a class="link" href="http://spark.apache.org/docs/1.6.0/api/python/pyspark.html#pyspark.SparkContext.newAPIHadoopRDD" target="_blank" rel="noopener"
>newAPIHadoopRDD&lt;/a> 这个方法，这个方法需要使用 Java 的类，用这些类读取 HBase&lt;/p>
&lt;p>下面的示例代码默认 HBase 中的行键、列族名、列名和值都是字符串转成的 &lt;code>byte&lt;/code> 数组：&lt;/p>
&lt;p>read_hbase_pyspark.py&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># -*- coding:utf-8 -*-&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">json&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pyspark&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">SparkContext&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pyspark&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">SparkConf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;__main__&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SparkConf&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;spark.executorEnv.PYTHONHASHSEED&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;0&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;spark.kryoserializer.buffer.max&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;2040mb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SparkContext&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">appName&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;HBaseInputFormat&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 配置项要包含 zookeeper 的 ip&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zookeeper_host&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;zkServer&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 还要包含要读取的 HBase 表名&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hbase_table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;testTable&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;hbase.zookeeper.quorum&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">zookeeper_host&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;hbase.mapreduce.inputtable&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">hbase_table_name&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 这个Java类用来将 HBase 的行键转换为字符串&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keyConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.ImmutableBytesWritableToStringConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 这个Java类用来将 HBase 查询得到的结果，转换为字符串&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">valueConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.HBaseResultToStringConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 第一个参数是 hadoop 文件的输入类型&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 第二个参数是 HBase rowkey 的类型&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 第三个参数是 HBase 值的类型&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 这三个参数不用改变&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 读取后的 rdd，每个元素是一个键值对，(key, value)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hbase_rdd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">newAPIHadoopRDD&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.mapreduce.TableInputFormat&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.io.ImmutableBytesWritable&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.client.Result&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keyConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keyConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">valueConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">valueConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 读取后，将键值对 (key, value) 中的值 value，使用\n切分，用 flatMap 展开&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 然后将键值对 (key, value) 中的值 value 使用 json.loads 解析，得到 dict&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hbase_rdd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hbase_rdd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">flatMapValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mapValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loads&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hbase_rdd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">collect&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">k&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">k&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>上述代码在提交给 spark 集群的时候，要指名用到的 Java 类的位置，这些类都在 spark-examples 这个包里面，这个包在 spark 目录下的 lib 里面。以 CDH 5.7.2 为例，CDH 集群中这个包的位置在 &lt;code>/opt/cloudera/parcels/CDH-5.7.2-1.cdh5.7.2.p0.18/lib/spark/lib/spark-examples-1.6.0-cdh5.7.2-hadoop2.6.0-cdh5.7.2.jar&lt;/code>，所以提交命令为：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">spark-submit --master yarn --jars /opt/cloudera/parcels/CDH-5.7.2-1.cdh5.7.2.p0.18/lib/spark/lib/spark-examples-1.6.0-cdh5.7.2-hadoop2.6.0-cdh5.7.2.jar read_hbase_pyspark.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>所以，上述的 Java 类，核心都是认为 HBase 中所有的值，原本都是字符串，然后转换成 &lt;code>byte&lt;/code> 数组后存入的 HBase，它在解析的时候，将读取到的 &lt;code>byte[]&lt;/code> 转换为字符串后返回，所以我们拿到的值就是字符串。&lt;/p>
&lt;h2 id="进阶方法">进阶方法
&lt;/h2>&lt;p>对于其他类型的数据，转换为 &lt;code>byte&lt;/code> 数组后存入 HBase，如果我们还使用上面的 Java 类去读取 HBase，那么我们拿到的字符串的值就是不正确的。&lt;/p>
&lt;p>为了理解这些内容，我们首先要讨论 HBase 中值的存储结构。&lt;/p>
&lt;p>HBase 是非结构化数据库，以行为单位，每行拥有一个行键 rowkey，对应的值可以表示为一个 map（python 中的 dict），举个例子，如果我们有一条记录，行键记为 &amp;ldquo;r1&amp;rdquo;，里面有 1 个列族(columnFamily) &amp;ldquo;A&amp;rdquo;，列族中有两列(qualifier)，分别记为 &amp;ldquo;a&amp;rdquo; 和 &amp;ldquo;b&amp;rdquo;，对应的值分别为 &amp;ldquo;v1&amp;rdquo; 和 &amp;ldquo;v2&amp;rdquo;，那么表示成 json 字符串就是下面的形式：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;r1&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;A&amp;#34;&lt;/span> &lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;a&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;v1&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;b&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;v2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>上面这个 json 字符串就是上面那条记录在 HBase 中存储的示例，第一层的键表示行键(rowkey)，对应的值表示这一行的值；第二层的键表示列族名(columnFamily)，值表示这个列族下列的值；第三层的键表示列名(qualifier)，对应的值(value)表示这个由行键、列族名、列名三项确定的一个单元格(Cell)内的值。所以上面这个例子中，只有一行，两个单元格。&lt;/p>
&lt;p>下面我们针对 pyspark 读取 HBase 使用到的 &lt;code>org.apache.spark.examples.pythonconverters.HBaseResultToStringConverter&lt;/code> 来讨论。&lt;/p>
&lt;p>Java 的 API 在读取 HBase 的时候，会得到一个 &lt;code>Result&lt;/code> 类型，这个 &lt;code>Result&lt;/code> 就是查询结果。&lt;code>Result&lt;/code> 可以遍历，里面拥有多个 &lt;code>Cell&lt;/code>，也就是单元格。上面我们说了，每个单元格至少有 4 个内容：行键、列族名、列名、值。&lt;/p>
&lt;p>&lt;code>HBaseResultToStringConverter&lt;/code> 是由 scala 实现的一个类，它的功能是将 Java HBase API 的 &lt;code>Result&lt;/code> 转换为 &lt;code>String&lt;/code>，源码如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">package&lt;/span> &lt;span class="nn">org.apache.spark.examples.pythonconverters&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">scala.collection.JavaConverters._&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">scala.util.parsing.json.JSONObject&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.spark.api.python.Converter&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.client.&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="nc">Put&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nc">Result&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.util.Bytes&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.KeyValue.Type&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.CellUtil&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">HBaseResultToStringConverter&lt;/span> &lt;span class="k">extends&lt;/span> &lt;span class="nc">Converter&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Any&lt;/span>, &lt;span class="kt">String&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">override&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">convert&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Any&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">String&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asInstanceOf&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Result&lt;/span>&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">listCells&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asScala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span> &lt;span class="k">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Map&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;row&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneRow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;columnFamily&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;qualifier&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneQualifier&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;timestamp&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;type&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Type&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">codeToType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTypeByte&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;value&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">JSONObject&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">_&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="n">mkString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;\n&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>它完成的工作是遍历 &lt;code>Result&lt;/code> 中的 &lt;code>Cell&lt;/code>，每个 &lt;code>Cell&lt;/code> 转换成一个 scala &lt;code>Map&lt;/code>，键分别是行键、列族名、列名、时间戳、HBase 操作类型、值。最后每个 scala &lt;code>Map&lt;/code> 被转换成 json 字符串，之间用 &amp;lsquo;\n&amp;rsquo; 分隔。&lt;/p>
&lt;p>这里的 &lt;code>CellUtil.CloneRow&lt;/code>，&lt;code>CellUtil.cloneFamily&lt;/code>，&lt;code>CellUtil.cloneQualifier&lt;/code>，&lt;code>CellUtil.cloneValue&lt;/code> 是我们主要使用的四个方法，这四个方法生成的都是 &lt;code>byte[]&lt;/code>，然后这四个 &lt;code>byte[]&lt;/code> 都被 &lt;code>Bytes.toStringBinary&lt;/code> 转换成了 &lt;code>String&lt;/code> 类型。&lt;/p>
&lt;p>所以，如果我们存入 HBase 的数据是 &lt;code>String&lt;/code> 以外类型的，如 &lt;code>Float&lt;/code>, &lt;code>Double&lt;/code>, &lt;code>BigDecimal&lt;/code>，那么这里使用 &lt;code>CellUtil&lt;/code> 的方法拿到 &lt;code>byte[]&lt;/code> 后，需要使用 &lt;code>Bytes&lt;/code> 里面的对应方法转换为原来的类型，再转成字符串或其他类型，生成 json 字符串，然后返回，这样我们通过 pyspark 才能拿到正确的值。&lt;/p>
&lt;p>下面是一个示例，我们的数据都是 &lt;code>java.math.BigDecimal&lt;/code> 类型的值，存 HBase 的时候将他们转换为 &lt;code>byte[]&lt;/code> 后进行了存储。那么解析的时候，就需要自定义一个处理 &lt;code>BigDecimal&lt;/code> 的类：&lt;code>HBaseResultToBigDecimalToStringConverter&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">package&lt;/span> &lt;span class="nn">org.apache.spark.examples.pythonconverters&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">java.math.BigDecimal&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">scala.collection.JavaConverters._&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">scala.util.parsing.json.JSONObject&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.spark.api.python.Converter&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.client.&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="nc">Put&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nc">Result&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.io.ImmutableBytesWritable&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.util.Bytes&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.KeyValue.Type&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.CellUtil&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">HBaseResultToBigDecimalToStringConverter&lt;/span> &lt;span class="k">extends&lt;/span> &lt;span class="nc">Converter&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Any&lt;/span>, &lt;span class="kt">String&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">override&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">convert&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Any&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">String&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asInstanceOf&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Result&lt;/span>&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">listCells&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asScala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span> &lt;span class="k">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Map&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;row&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneRow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;columnFamily&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;qualifier&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneQualifier&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;timestamp&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;type&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Type&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">codeToType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTypeByte&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;value&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBigDecimal&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">JSONObject&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">_&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="n">mkString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;\n&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>上述代码中，引入了 &lt;code>java.math.BigDecimal&lt;/code>，将 &lt;code>value&lt;/code> 的解析进行了简单的修改，通过 &lt;code>CellUtil.cloneValue&lt;/code> 拿到 &lt;code>byte[]&lt;/code> 后，通过 &lt;code>Bytes.toBigDecimal&lt;/code> 转换成 &lt;code>java.math.BigDecimal&lt;/code>，然后使用 &lt;code>toString&lt;/code> 方法转换成字符串。&lt;/p>
&lt;p>这个类写完后，我们就可以对其进行编译，导出成 jar 包，在 pyspark 程序中指明，读取的时候，使用这个类解析 value。&lt;/p>
&lt;p>这样源代码就改完了，需要编译成 jar 包。&lt;/p>
&lt;p>首先安装 &lt;a class="link" href="http://maven.apache.org/" target="_blank" rel="noopener"
>maven&lt;/a> 3.6.0，下载后，解压，配置环境变量即可。&lt;/p>
&lt;p>下载 spark 的源码，去 Apache Spark 官网，下载仓库中的源代码 &lt;a class="link" href="https://archive.apache.org/dist/spark/spark-1.6.0/" target="_blank" rel="noopener"
>spark-1.6.0.tgz&lt;/a> 。&lt;/p>
&lt;p>下载后解压，将根目录中的 scalastyle-config.xml 拷贝到 examples 目录下。&lt;/p>
&lt;p>修改 &lt;code>examples/src/main/scala/org/apache/spark/examples/pythonconverters/HBaseConverters.scala&lt;/code>，增加自己用的类。&lt;/p>
&lt;p>修改 &lt;code>examples/pom.xml&lt;/code>，将 &lt;code>&amp;lt;artifactId&amp;gt;spark-examples_2.10&amp;lt;/artifactId&amp;gt;&lt;/code> 修改为 &lt;code>&amp;lt;artifactId&amp;gt;spark-examples_2.10_my_converters&amp;lt;/artifactId&amp;gt;&lt;/code>。&lt;/p>
&lt;p>cd 到 examples 目录下，使用以下命令编译 spark-examples&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">mvn clean install -pl :spark-examples_2.10_my_converters
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>编译途中保证全程联网，编译的时候会有一些警告，编译好的包在同级目录下的 target 中，有个叫 spark-examples_2.10_my_converters-1.6.0.jar 的文件。&lt;/p>
&lt;p>然后就是使用这个包读取 HBase 中的 BigDecimal了：&lt;/p>
&lt;p>我们使用 standalone 模式运行 pyspark 交互式界面：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">pyspark --master spark://host1:7077 --jars spark-examples_2.10_my_converters-1.6.0.jar
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>执行以下内容：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">json&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">zookeeper_host&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;host1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;testTable&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;hbase.zookeeper.quorum&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">zookeeper_host&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;hbase.mapreduce.inputtable&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">hbase_table_name&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">keyConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.ImmutableBytesWritableToStringConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 注意这里，使用自己定义的Converter读取&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">valueConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.HBaseResultToBigDecimalToStringConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_rdd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">newAPIHadoopRDD&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.mapreduce.TableInputFormat&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.io.ImmutableBytesWritable&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.client.Result&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keyConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keyConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">valueConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">valueConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_rdd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hbase_rdd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">flatMapValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mapValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loads&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_rdd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">take&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后就可以看到结果了，如何验证读取的对不对呢，可以尝试将 &lt;code>valueConv&lt;/code> 改回 &lt;code>HBaseResultToStringConverter&lt;/code>，然后观察 value 的值。&lt;/p>
&lt;p>以上就是如何通过修改 HBaseConverters.scala 让 pyspark 从 HBase 中读取 &lt;code>java.math.BigDecimal&lt;/code> 的示例。&lt;/p>
&lt;h1 id="pyspark-写入-hbase">pyspark 写入 HBase
&lt;/h1>&lt;p>pyspark 写入 HBase 使用 &lt;code>SparkContext&lt;/code> 的 &lt;a class="link" href="http://spark.apache.org/docs/1.6.0/api/python/pyspark.html#pyspark.RDD.saveAsNewAPIHadoopDataset" target="_blank" rel="noopener"
>saveAsNewAPIHadoopDataset&lt;/a>，和读取的方法类似，也需要使用 Java 的类。&lt;/p>
&lt;p>&lt;strong>下面的方法要求存入 HBase 中的数据，行键、列族名、列名、值都为字符串&lt;/strong>&lt;/p>
&lt;p>write_into_hbase_pyspark.py&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># -*- coding:utf-8 -*-&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pyspark&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">SparkContext&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pyspark&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">SparkConf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;__main__&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SparkConf&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;spark.executorEnv.PYTHONHASHSEED&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;0&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">set&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;spark.kryoserializer.buffer.max&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;2040mb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SparkContext&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">appName&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;HBaseOutputFormat&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 配置项要包含 zookeeper 的 ip&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zookeeper_host&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;zkServer&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 还要包含要写入的 HBase 表名&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hbase_table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;testTable&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;hbase.zookeeper.quorum&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">zookeeper_host&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;hbase.mapred.outputtable&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">hbase_table_name&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;mapreduce.outputformat.class&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.mapreduce.TableOutputFormat&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;mapreduce.job.output.key.class&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.io.ImmutableBytesWritable&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;mapreduce.job.output.value.class&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;org.apache.hadoop.io.Writable&amp;#34;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keyConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.StringToImmutableBytesWritableConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">valueConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.StringListToPutConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">records&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;row1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;f1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;q1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;value1&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;row2&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;f1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;q1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;value2&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;row3&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;f1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;q1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;value3&amp;#39;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;row4&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;f1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;q1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;value4&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parallelize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">records&lt;/span>&lt;span class="p">)&lt;/span>\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">saveAsNewAPIHadoopDataset&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keyConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keyConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">valueConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">valueConv&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>首先在控制台启动 HBase-shell&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">hbase shell
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后创建表，表名为 testTable，只有一个列族，列族名为 f1：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">create &lt;span class="s1">&amp;#39;testTable&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;f1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用 &lt;code>quit&lt;/code> 退出 HBase-shell&lt;/p>
&lt;p>提交 pyspark 程序：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">spark-submit --master spark://master:7077 --jars /opt/cloudera/parcels/CDH-5.7.2-1.cdh5.7.2.p0.18/lib/spark/lib/spark-examples-1.6.0-cdh5.7.2-hadoop2.6.0-cdh5.7.2.jar write_into_hbase_pyspark.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>运行完成后，再次进入 HBase-shell，运行：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">scan &lt;span class="s1">&amp;#39;testTable&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以看到类似下面的输出结果：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">hbase(main):001:0&amp;gt; scan &amp;#39;testTable&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ROW COLUMN+CELL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> row1 column=f1:q1, timestamp=1554892784494, value=value1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> row2 column=f1:q1, timestamp=1554892784494, value=value2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> row3 column=f1:q1, timestamp=1554892816961, value=value3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> row4 column=f1:q1, timestamp=1554892816961, value=value4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 row(s) in 0.3330 seconds
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这就完成了写入 HBase 的过程。&lt;/p>
&lt;p>&lt;strong>需要注意的是：rdd 中的每个元素，都必须是一个列表(&lt;code>list&lt;/code>)，不能是其他类型，如 &lt;code>tuple&lt;/code>，而且每个列表内必须是 4 个元素，分别表示 &lt;code>[行键、列族名、列名、值]&lt;/code>，且每个元素都为 &lt;code>str&lt;/code> 类型。&lt;/strong>&lt;/p>
&lt;p>原因是 &lt;code>StringListToPutConverter&lt;/code> 这个类做转换的时候需要将 rdd 中的元素，看作是一个 &lt;code>java.util.ArrayList[String]&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">StringListToPutConverter&lt;/span> &lt;span class="k">extends&lt;/span> &lt;span class="nc">Converter&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Any&lt;/span>, &lt;span class="kt">Put&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">override&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">convert&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Any&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Put&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asInstanceOf&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">java.util.ArrayList&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">String&lt;/span>&lt;span class="o">]].&lt;/span>&lt;span class="n">asScala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBytes&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toArray&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">put&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nc">Put&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">put&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>StringListToPutConverter&lt;/code> 的工作原理是，将传入的元素强制类型转换为 &lt;code>java.util.ArrayList[String]&lt;/code>，将第一个元素作为行键、第二个元素作为列族名、第三个元素作为列名、第四个元素作为值，四个值都转换为 &lt;code>byte[]&lt;/code> 后上传至 HBase。&lt;/p>
&lt;p>所以我们可以修改这个类，实现存入类型的多样化。&lt;/p>
&lt;p>举个例子，如果我想存入一个 &lt;code>java.math.BigDecimal&lt;/code>，那实现的方法就是：在 pyspark 程序中，将数字转换成 &lt;code>str&lt;/code> 类型，调用我们自己写的一个 converter：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">java.math.BigDecimal&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">StringListToBigDecimalToPutConverter&lt;/span> &lt;span class="k">extends&lt;/span> &lt;span class="nc">Converter&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Any&lt;/span>, &lt;span class="kt">Put&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">override&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">convert&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Any&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Put&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asInstanceOf&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">java.util.ArrayList&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">String&lt;/span>&lt;span class="o">]].&lt;/span>&lt;span class="n">asScala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toArray&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">put&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nc">Put&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">put&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="nc">BigDecimal&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="o">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>就可以实现存入的值是 &lt;code>java.math.BigDecimal&lt;/code> 了。&lt;/p>
&lt;h1 id="cdh-59-以前的版本python3master-选定为-yarn-时的-bug">CDH 5.9 以前的版本，python3，master 选定为 yarn 时的 bug
&lt;/h1>&lt;p>CDH 5.9 以前的版本在使用 yarn 作为 spark master 的时候，如果使用 python3，会出现 yarn 內部 &lt;code>topology.py&lt;/code> 这个文件引发的 bug。这个文件是 python2 的语法，我们使用 python3 运行任务的时候，python3 的解释器在处理这个文件时会出错。&lt;/p>
&lt;p>解决方案是：将这个文件重写为 python3 的版本，每次在重启 yarn 之后，将这个文件复制到所有机器的 &lt;code>/etc/hadoop/conf.cloudera.yarn/&lt;/code>目录下。&lt;/p>
&lt;p>以下是 python3 版本的 &lt;code>topology.py&lt;/code>。&lt;/p>
&lt;p>&lt;code>topology.py&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="ch">#!/usr/bin/env python&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Copyright (c) 2010-2012 Cloudera, Inc. All rights reserved.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">This script is provided by CMF for hadoop to determine network/rack topology.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">It is automatically generated and could be replaced at any time. Any changes
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">made to it will be lost when this happens.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">xml.dom.minidom&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MAP_FILE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;{{CMF_CONF_DIR}}/topology.map&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">DEFAULT_RACK&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/default&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="s1">&amp;#39;CMF_CONF_DIR&amp;#39;&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">MAP_FILE&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># variable was not substituted. Use this file&amp;#39;s dir&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MAP_FILE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dirname&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="vm">__file__&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="s2">&amp;#34;topology.map&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># We try to keep the default rack to have the same&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># number of elements as the other hosts available.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># There are bugs in some versions of Hadoop which&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># make the system error out.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">max_elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">map&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">dict&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mapFile&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">MAP_FILE&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;r&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dom&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">xml&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dom&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">minidom&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parse&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mapFile&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">dom&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getElementsByTagName&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;node&amp;#34;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rack&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">node&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getAttribute&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;rack&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">max_elements&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_elements&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">rack&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;/&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">map&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">node&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getAttribute&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">)]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">node&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getAttribute&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;rack&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">default_rack&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">([&lt;/span> &lt;span class="n">DEFAULT_RACK&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_elements&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default_rack&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">default_rack&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">([&lt;/span> &lt;span class="n">DEFAULT_RACK&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_elements&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">default_rack&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">map&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">default_rack&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:]]))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;__main__&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">main&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>pyspark中的HBaseConverters</title><link>https://davidham3.github.io/blog/p/pyspark%E4%B8%AD%E7%9A%84hbaseconverters/</link><pubDate>Sat, 06 Apr 2019 16:43:29 +0000</pubDate><guid>https://davidham3.github.io/blog/p/pyspark%E4%B8%AD%E7%9A%84hbaseconverters/</guid><description>&lt;p>最近项目上有个需求，使用 pyspark 读取 HBase 中存储的 java.math.BigDecimal。&lt;/p>
&lt;p>最近甲方让我们写一个 pyspark 的教程，他们以后打算使用 pyspark 开发。他们的数据是那种精度要求比较高的数据，我们使用 java.math.BigDecimal 表示数字，然后转成 byte[] 后存入了 HBase，但是 python 是没法直接读取这个 BigDecimal，所以需要使用 spark-examples 中 HBaseConverters.scala 读取。&lt;/p>
&lt;p>我们讨论的 spark 版本是 1.6，因为用的是 CDH 5，所以是这个版本。&lt;/p>
&lt;p>原理实际上是，pyspark 在读取 HBase 的时候需要借助 org.apache.spark.examples.pythonconverters 这么一个类，这个类实际上是 scala 将 HBase 中的数据读取后，转换成 json 字符串返回，这样 pyspark 可以通过这个类从 HBase 中直接获取到 json 字符串这样的返回值。&lt;/p>
&lt;p>可以从 &lt;a class="link" href="https://github.com/apache/spark/blob/branch-1.6/examples/src/main/scala/org/apache/spark/examples/pythonconverters/HBaseConverters.scala" target="_blank" rel="noopener"
>HBaseConverters.scala&lt;/a> 这里看到 HBaseConverters.scala 的源码，我们感兴趣的是从 HBase 中查询 value 这一部分：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">package&lt;/span> &lt;span class="nn">org.apache.spark.examples.pythonconverters&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">scala.collection.JavaConverters._&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">scala.util.parsing.json.JSONObject&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.spark.api.python.Converter&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.client.&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="nc">Put&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="nc">Result&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.io.ImmutableBytesWritable&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.util.Bytes&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.KeyValue.Type&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.CellUtil&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cm">/**
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cm"> * Implementation of [[org.apache.spark.api.python.Converter]] that converts all
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cm"> * the records in an HBase Result to a String
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cm"> */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">HBaseResultToStringConverter&lt;/span> &lt;span class="k">extends&lt;/span> &lt;span class="nc">Converter&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Any&lt;/span>, &lt;span class="kt">String&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">override&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">convert&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Any&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">String&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asInstanceOf&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Result&lt;/span>&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">listCells&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asScala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span> &lt;span class="k">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Map&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;row&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneRow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;columnFamily&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;qualifier&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneQualifier&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;timestamp&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;type&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Type&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">codeToType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTypeByte&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;value&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">JSONObject&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">_&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="n">mkString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;\n&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这段代码很简单，实际上就是使用 java HBase 的 API 读取 HBase 中的值，将所有的值转换为 String 返回，我需要做的，只是将 value 这个字段的值，先从 byte[] 转到 BigDecimal，再转换为 String 即可。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-scala" data-lang="scala">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">MyHBaseResultToStringConverter&lt;/span> &lt;span class="k">extends&lt;/span> &lt;span class="nc">Converter&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Any&lt;/span>, &lt;span class="kt">String&lt;/span>&lt;span class="o">]&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">override&lt;/span> &lt;span class="k">def&lt;/span> &lt;span class="n">convert&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">Any&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="k">:&lt;/span> &lt;span class="kt">String&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asInstanceOf&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="kt">Result&lt;/span>&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="n">output&lt;/span> &lt;span class="k">=&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">listCells&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asScala&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span> &lt;span class="k">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Map&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;row&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneRow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;columnFamily&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneFamily&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;qualifier&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toStringBinary&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneQualifier&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;timestamp&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTimestamp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;type&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Type&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">codeToType&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getTypeByte&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;value&amp;#34;&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nc">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toBigDecimal&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cloneValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">cell&lt;/span>&lt;span class="o">)).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nc">JSONObject&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">_&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="n">toString&lt;/span>&lt;span class="o">()).&lt;/span>&lt;span class="n">mkString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;\n&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这样代码就改完了，然后需要编译，打成 jar 包。&lt;/p>
&lt;p>装好 maven，我装的是 3.6.0，不需要配置什么。&lt;/p>
&lt;p>下载 spark 的源码，最开始我从 github 上面下载的，发现速度很慢，然后就去 spark 官网，找仓库中的源代码下载下来。&lt;/p>
&lt;p>编译 spark-examples 的时候需要先从根目录中把 scalastyle-config.xml 拷贝到 examples 目录下再进行编译&lt;/p>
&lt;p>cd 到 examples 目录下，使用以下命令编译 spark-examples&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">mvn clean install -pl :spark-examples_2.10
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://davidham3.github.io/blog/blog/images/pyspark%e4%b8%ad%e7%9a%84hbaseconverters/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>编译的时候没有遇到错误，编译好的包在同级目录下的 target 中，有个叫 spark-examples_2.10-1.6.0.jar 的文件。&lt;/p>
&lt;p>然后就是使用这个包读取 HBase 中的 BigDecimal了：&lt;/p>
&lt;p>我们使用 standalone 模式运行 pyspark：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">pyspark --master spark://host1:7077 --jars spark-examples_2.10-1.6.0.jar
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">json&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">zookeeper_host&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;host1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;testTable&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;hbase.zookeeper.quorum&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">zookeeper_host&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;hbase.mapreduce.inputtable&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">hbase_table_name&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">keyConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.ImmutableBytesWritableToStringConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 注意这里，使用自己定义的Converter读取&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">valueConv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;org.apache.spark.examples.pythonconverters.MyHBaseResultToStringConverter&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_rdd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">newAPIHadoopRDD&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.mapreduce.TableInputFormat&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.io.ImmutableBytesWritable&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;org.apache.hadoop.hbase.client.Result&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keyConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keyConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">valueConverter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">valueConv&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">conf&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_rdd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hbase_rdd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">flatMapValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mapValues&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">json&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loads&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hbase_rdd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">take&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后就可以看到结果了。&lt;/p>
&lt;p>以上就是如何通过修改 HBaseConverters.scala 让 pyspark 从 HBase 中读取 java 的特殊类型。&lt;/p></description></item><item><title>Kafka生产者与消费者</title><link>https://davidham3.github.io/blog/p/kafka%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85/</link><pubDate>Thu, 05 Jul 2018 20:54:26 +0000</pubDate><guid>https://davidham3.github.io/blog/p/kafka%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85/</guid><description>&lt;p>Kafka是一个分布式、流式消息平台，是一套发布订阅系统，通俗来说就是Kafka producer发布数据至Kafka brokers，然后由Kafka consumer从brokers拉取数据，进行消费。&lt;/p>
&lt;p>最近上数据仓库的课，学习了Kafka的使用方式以及Kafka的原理。&lt;/p>
&lt;p>Kafka官网：&lt;a class="link" href="http://kafka.apache.org/" target="_blank" rel="noopener"
>Apache Kafka&lt;/a>&lt;/p>
&lt;p>Kafka是一个分布式、流式消息平台，是一套发布订阅系统，通俗来说就是Kafka producer发布数据至Kafka brokers，然后由Kafka consumer从brokers拉取数据，进行消费。&lt;/p>
&lt;p>&lt;strong>日志&lt;/strong>
有意思的特性是Kafka内的数据都是以日志的形式存储，即便消费完也不会消失，配置文件中配置了过了多长时间日志会销毁掉。这样设计的好处有很多，consumer是有group的，每个组进行消费的时候，都会有个偏移量offset记录在zookeeper中，通过这个offset就知道下次从哪里开始消费了，不同组的offset不一样，这样每个组都可以按照自己的需要进行消费。&lt;/p>
&lt;p>&lt;strong>主题&lt;/strong>
Kafka的记录是有主题的，这样producer发送到broker的数据其实就是打上了标签，有了分类，消费的时候可以按主题消费，相当于一开始就用主题对数据进行了区分。&lt;/p>
&lt;p>&lt;strong>效率&lt;/strong>
Kafka集群同时也作为缓冲区，平衡producer和consumer两边的工作进度，不会因为一方过慢造成阻塞一类的问题。&lt;/p>
&lt;p>&lt;strong>语言&lt;/strong>
写起来的话，肯定是java和scala最好，因为Kafka就是由这两种语言编写的，当然，也有其他语言的接口，比如python。python的话比较有意思的是有两个Kafka框架，一个是&lt;a class="link" href="https://kafka-python.readthedocs.io/en/master/index.html" target="_blank" rel="noopener"
>kafka-python&lt;/a>，另一个是&lt;a class="link" href="http://pykafka.readthedocs.io/en/latest/#" target="_blank" rel="noopener"
>pykafka&lt;/a>。推荐使用后者，前者在创建consumer group的时候不是很方便，group内的每个consumer消费的内容都一样，没有实现去重与平衡，这些都需要自己实现，后者的balanced_consumer就挺好的。&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/Davidham3/pykafka_examples" target="_blank" rel="noopener"
>自己写的例子&lt;/a>&lt;/p></description></item><item><title>迁移CentOS7虚拟机mac和网卡名变换导致网络不通的问题</title><link>https://davidham3.github.io/blog/p/%E8%BF%81%E7%A7%BBcentos7%E8%99%9A%E6%8B%9F%E6%9C%BAmac%E5%92%8C%E7%BD%91%E5%8D%A1%E5%90%8D%E5%8F%98%E6%8D%A2%E5%AF%BC%E8%87%B4%E7%BD%91%E7%BB%9C%E4%B8%8D%E9%80%9A%E7%9A%84%E9%97%AE%E9%A2%98/</link><pubDate>Tue, 12 Jun 2018 11:15:17 +0000</pubDate><guid>https://davidham3.github.io/blog/p/%E8%BF%81%E7%A7%BBcentos7%E8%99%9A%E6%8B%9F%E6%9C%BAmac%E5%92%8C%E7%BD%91%E5%8D%A1%E5%90%8D%E5%8F%98%E6%8D%A2%E5%AF%BC%E8%87%B4%E7%BD%91%E7%BB%9C%E4%B8%8D%E9%80%9A%E7%9A%84%E9%97%AE%E9%A2%98/</guid><description>&lt;p>vcenter迁移虚拟机的时候，迁移之后虚拟机网络不通。&lt;/p>
&lt;p>参考：&lt;a class="link" href="https://www.jianshu.com/p/29af2068cfb6" target="_blank" rel="noopener"
>解决CentOS 7虚拟机克隆的网络问题&lt;/a>&lt;/p>
&lt;p>使用vcenter的迁移后，虚拟机出现了网络不通的现象，仔细观察可以发现vcenter给虚拟机分配了新的mac地址。
因为Linux系统会记录mac地址与网卡名的关系，所以Linux系统在运行后，发现mac变了，于是会给当前这张网卡分配一个新的网卡名。
解决方案就是：&lt;/p>
&lt;ol>
&lt;li>修改网卡配置文件/etc/sysconfig/network-scripts/ifcfg-eno16884287
删除UUID这一行，因为每张网卡的mac地址是不一样的，所以UUID也是不一样的。
修改HWADDR为虚拟机克隆后的MAC地址&lt;/li>
&lt;li>进入/etc/udev/rules.d/这个目录，将里面的.rules文件改名
&lt;code>mv 70-persistent-ipoib.rules 70-persistent-ipoib.rules.bak&lt;/code>
&lt;code>mv 90-eno-fix.rules 90-eno-fix.rules.bak&lt;/code>&lt;/li>
&lt;li>重启
&lt;code>reboot&lt;/code>&lt;/li>
&lt;/ol></description></item><item><title>Hadoop HA安装三：zookeeper的安装</title><link>https://davidham3.github.io/blog/p/hadoop-ha%E5%AE%89%E8%A3%85%E4%B8%89zookeeper%E7%9A%84%E5%AE%89%E8%A3%85/</link><pubDate>Mon, 21 Aug 2017 16:13:59 +0000</pubDate><guid>https://davidham3.github.io/blog/p/hadoop-ha%E5%AE%89%E8%A3%85%E4%B8%89zookeeper%E7%9A%84%E5%AE%89%E8%A3%85/</guid><description>&lt;p>zookeeper通常以“复制模式”运行于一个计算机集群上，这个计算机集群被称为一个“集合体”。zookeeper通过复制来实现高可用性，只要集合体中半数以上的机器处于可用状态，它就可以提供服务。出于这个原因，一个集合体通常包含奇数台机器。&lt;/p>
&lt;h1 id="zookeeper的安装">zookeeper的安装
&lt;/h1>&lt;p>zookeeper通常以“复制模式”运行于一个计算机集群上，这个计算机集群被称为一个“集合体”。zookeeper通过复制来实现高可用性，只要集合体中半数以上的机器处于可用状态，它就可以提供服务。出于这个原因，一个集合体通常包含奇数台机器。&lt;/p>
&lt;h2 id="安装">安装
&lt;/h2>&lt;p>本文选择了在cluster2，cluster3和cluster4三台机器上安装
将zookeeper解压到/usr/local目录下，并配置环境变量
&lt;code># vi /etc/profile&lt;/code>
在最下面加上2行&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">ZOOKEEPER_HOME&lt;/span>&lt;span class="o">=/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">local&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">zookeeper&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mf">3.4&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="mi">6&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">PATH&lt;/span>&lt;span class="o">=$&lt;/span>&lt;span class="n">ZOOKEEPER&lt;/span>\&lt;span class="n">_HOME&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bin&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后在conf中新建zoo.cfg文件，输入以下内容：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># 客户端心跳时间(毫秒)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tickTime=2000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 允许心跳间隔的最大时间
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">initLimit=10
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 同步时限
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">syncLimit=5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 数据存储目录
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dataDir=/home/hadoop_files/hadoop_data/zookeeper
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 数据日志存储目录
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dataLogDir=/home/hadoop_files/hadoop_logs/zookeeper/dataLog
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 端口号
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">clientPort=2181
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 集群节点和服务端口配置
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server.1=hadoop-cluster2:2888:3888
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server.2=hadoop-cluster3:2888:3888
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server.3=hadoop-cluster4:2888:3888
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>创建zookeeper的数据存储目录和日志存储目录&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># mkdir -p /home/hadoop_files/hadoop_data/zookeeper
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># mkdir -p /home/hadoop_files/hadoop_logs/zookeeper/dataLog
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># mkdir -p /home/hadoop_files/hadoop_logs/zookeeper/logs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>修改文件夹的权限&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># chown -R hadoop:hadoop /home/hadoop_files
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># chown -R hadoop:hadoop /usr/local/zookeeper-3.4.6
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在cluster2号服务器的data目录中创建一个文件myid，输入内容为1，myid应与zoo.cfg中的集群节点相匹配&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># echo &amp;#34;1&amp;#34; &amp;gt;&amp;gt; /home/hadoop_files/hadoop_data/zookeeper/myid
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>修改zookeeper的日志输出路径
&lt;code># vi bin/zkEnv.sh&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if [ &amp;#34;x${ZOO\_LOG\_DIR}&amp;#34; = &amp;#34;x&amp;#34; ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">then
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ZOO\_LOG\_DIR=&amp;#34;/home/hadoop\_files/hadoop\_logs/zookeeper/logs&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">fi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if [ &amp;#34;x${ZOO_LOG4J_PROP}&amp;#34; = &amp;#34;x&amp;#34; ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">then
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ZOO_LOG4J_PROP=&amp;#34;INFO,ROLLINGFILE&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">fi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>修改zookeeper的日志配置文件
&lt;code># vi conf/log4j.properties&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">zookeeper.root.logger=INFO,ROLLINGFILE
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">log4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>将这个zookeeper-3.4.6的目录复制到其他的两个节点上&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># scp -r /usr/local/zookeeper-3.4.6 cluster3:/usr/local/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># scp -r /usr/local/zookeeper-3.4.6 cluster4:/usr/local/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>复制后在那两台机器上使用root用户修改目录所有者为hadoop用户，并修改他们的myid为2和3。&lt;/p>
&lt;p>退回hadoop用户&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># exit
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后使用hadoop用户，使用&lt;code>zkServer.sh start&lt;/code>分别启动三个zookeeper，顺序无所谓。三个都启动后，使用&lt;code>jps&lt;/code>命令查看，若有QuorumPeerMain则说明服务正常启动，没有的话，使用&lt;code>zkServer.sh start-foreground&lt;/code>查看一下哪里出了问题。&lt;/p>
&lt;h2 id="安装中遇到的问题">安装中遇到的问题
&lt;/h2>&lt;ol>
&lt;li>zookeeper启动不了
使用&lt;code>zkServer.sh start-foreground&lt;/code>运行zookeeper，显示&lt;code>line 131:exec java: not found&lt;/code>
解决办法：
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># cd /usr/local
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># chown –R hadoop:hadoop zookeeper-3.4.6
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>改一下用户权限即可&lt;/li>
&lt;li>打开logs文件夹里面的zookeeper.log显示connection refused错误
原因：一般来说这是配置的问题，我出现这个问题的主要原因是，我在zoo.cfg中写了三个server，但是只在server1上启动zkServer.sh所以会出现connection refused。
事实上只在一个机器上启动zookeeper时，使用&lt;code>zkServer.sh status&lt;/code>查看状态时，会显示zk可能没有运行，但是这并不是说明你的zookeeper有问题，只是那两个还没启动好而已，当3台机器的zookeeper都启动后，3台机器会自动进行投票，选出一个leader两个follower，此时再用&lt;code>zkServer.sh status&lt;/code>查看状态的时候就可以看到这台机器是leader还是follower了。&lt;/li>
&lt;/ol></description></item><item><title>Hadoop HA安装二：MySQL双机热备</title><link>https://davidham3.github.io/blog/p/hadoop-ha%E5%AE%89%E8%A3%85%E4%BA%8Cmysql%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/</link><pubDate>Mon, 21 Aug 2017 16:13:31 +0000</pubDate><guid>https://davidham3.github.io/blog/p/hadoop-ha%E5%AE%89%E8%A3%85%E4%BA%8Cmysql%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/</guid><description>&lt;p>Hadoop HA安装二：MySQL双机热备&lt;/p>
&lt;h2 id="安装mysql">安装MySQL
&lt;/h2>&lt;p>安装前先安装一下MySQL的依赖
ubuntu:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># apt-get install libaio-dev
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>CentOS:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># yum install libaio
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>看了很多教程都不靠谱。。。还是官方教程最靠谱：
&lt;a class="link" href="https://dev.mysql.com/doc/refman/5.6/en/binary-installation.html" target="_blank" rel="noopener"
>Installing MySQL on Unix/Linux Using Generic Binaries&lt;/a>&lt;/p>
&lt;p>下载mysql-5.6.37-linux-glibc2.12-x86_64
&lt;code># cp mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz /usr/local/&lt;/code>&lt;/p>
&lt;p>解压到/usr/local/
&lt;code># tar -zxvf mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz&lt;/code>&lt;/p>
&lt;p>改名为mysql
&lt;code># mv mysql-5.6.37-linux-glibc2.12-x86_64 mysql&lt;/code>&lt;/p>
&lt;p>删除安装包
&lt;code># rm mysql-5.6.37-linux-glibc2.12-x86_64.tar.gz&lt;/code>&lt;/p>
&lt;p>修改环境变量
&lt;code># vi /etc/profile&lt;/code>
在最下面添加&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">MYSQL_HOME&lt;/span>&lt;span class="o">=/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">local&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">mysql&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">PATH&lt;/span>&lt;span class="o">=$&lt;/span>&lt;span class="n">MYSQL_HOME&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bin&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>新建用户和用户组：mysql
&lt;code># groupadd mysql&lt;/code>
&lt;code># useradd -r -g mysql -s /bin/false mysql&lt;/code>&lt;/p>
&lt;p>&lt;code># cd /usr/local/mysql&lt;/code>&lt;/p>
&lt;p>修改目录的拥有者
&lt;code># chown -R mysql .&lt;/code>(&lt;strong>重要！&lt;/strong>)
&lt;code># chgrp -R mysql .&lt;/code>(&lt;strong>重要！&lt;/strong>)&lt;/p>
&lt;p>安装MySQL
&lt;code># scripts/mysql_install_db --user=mysql&lt;/code>&lt;/p>
&lt;p>修改当前目录拥有者为root用户
&lt;code># chown -R root .&lt;/code>&lt;/p>
&lt;p>修改当前data目录拥有者为mysql用户
&lt;code># chown -R mysql data&lt;/code>&lt;/p>
&lt;p>启动MySQL进程
&lt;code># bin/mysqld_safe --user=mysql &amp;amp;&lt;/code>&lt;/p>
&lt;p>此时这个窗口会卡住，新建一个terminal，进入/usr/local/mysql中&lt;/p>
&lt;p>进入mysql控制台
&lt;code># bin/mysql&lt;/code>&lt;/p>
&lt;p>退出
&lt;code>exit;&lt;/code>&lt;/p>
&lt;p>进行MySQL的root用户密码的修改等操作
&lt;code># ./bin/mysql_secure_installation&lt;/code>
首先要求输入root密码，由于我们没有设置过root密码，括号里面说了，如果没有root密码就直接按回车。是否设定root密码，选y，设定密码为cluster，是否移除匿名用户：y。然后有个是否关闭root账户的远程登录，选n，删除test这个数据库？y，更新权限？y，然后ok。&lt;/p>
&lt;p>&lt;code># cp support-files/mysql.server /etc/init.d/mysql.server&lt;/code>&lt;/p>
&lt;p>查看MySQL的进程号
&lt;code># ps -ef | grep mysql&lt;/code>&lt;/p>
&lt;p>如果有的话就kill掉，保证MySQL已经中断运行了，一般kill掉/usr/local/mysql/bin/mysqld开头的即可
&lt;code># kill 进程号&lt;/code>&lt;/p>
&lt;p>启动MySQL
&lt;code># /etc/init.d/mysql.server start -user=mysql&lt;/code>
&lt;code># exit&lt;/code>&lt;/p>
&lt;p>还需要配置一下访问权限：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ mysql -u root -p
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; GRANT ALL PRIVILEGES ON *.* TO &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;cluster&amp;#39; WITH GRANT OPTION;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; FLUSH PRIVILEGES;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这样就可以使用root用户在任意地点登陆，而不再限于localhost了
关于服务的三个命令。
启动mysql：&lt;code># /etc/init.d/mysql.server start -user=mysql&lt;/code>
停止mysql：&lt;code># mysqladmin -u root -p shutdown&lt;/code>&lt;/p>
&lt;h2 id="修改mysql的数据存储位置">修改MySQL的数据存储位置
&lt;/h2>&lt;p>在装系统进行分区的时候，有些时候会创建比较大的分区开存数据，我们可以将MySQL的数据存放到这个区内，假设这个区为/file0&lt;/p>
&lt;p>&lt;code>$ su root&lt;/code>&lt;/p>
&lt;p>把MySQL服务进程停掉：
&lt;code># mysqladmin -u root -p shutdown&lt;/code>&lt;/p>
&lt;p>新建新的dataDir
&lt;code># mkdir /file0/mysql_data&lt;/code>&lt;/p>
&lt;p>把/usr/local/mysql/data里面的东西移到/file0/mysql_data下
&lt;code># cp /usr/local/mysql/data/* /file0/mysql_data&lt;/code>&lt;/p>
&lt;p>编辑MySQL的配置文件/etc/my.cnf
如果没有的话，就把/usr/local/mysql里面的my.cnf复制过去
&lt;code># cp /usr/local/mysql/my.cnf /etc/&lt;/code>
&lt;code># vi /etc/my.cnf&lt;/code>&lt;/p>
&lt;p>把里面的basedir, datadir, port修改成下面的内容&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">basedir=/usr/local/mysql
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">datadir=/file0/mysql_data
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">port=3306
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>修改MySQL启动脚本/etc/init.d/mysql.server
&lt;code># vi /etc/init.d/mysql.server&lt;/code>
把里面的basedir和datadir作如上修改&lt;/p>
&lt;p>修改新目录的权限：
&lt;code># chown –R mysql /file0/mysql_data&lt;/code>
&lt;code># chgrp –R mysql /file0/mysql_data&lt;/code>
退出root用户
重新启动MySQL服务
&lt;code>$ /etc/init.d/mysql.server start –user=mysql&lt;/code>&lt;/p>
&lt;p>进入mysql
&lt;code>$ mysql –u root -p&lt;/code>&lt;/p>
&lt;p>查看目录是否已经更改
&lt;code>mysql&amp;gt; show variables like “datadir”;&lt;/code>&lt;/p>
&lt;h2 id="高可用的mysql双机热备安装教程">高可用的MySQL双机热备安装教程
&lt;/h2>&lt;p>开启二进制日志，设置id
&lt;code># vi /etc/my.cnf&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">[mysqld]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server-id = 1 #backup这台设置2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">log-bin = mysql-bin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">binlog-ignore-db = mysql,information_schema #忽略写入binlog日志的库
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">auto-increment-increment = 2 #字段变化增量值
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">auto-increment-offset = 1 #初始字段ID为1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">slave-skip-errors = all #忽略所有复制产生的错误
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>重启MySQL服务
&lt;code># mysqladmin -u root -p shutdown&lt;/code>
&lt;code># /etc/init.d/mysql.server start –user=mysql&lt;/code>&lt;/p>
&lt;p>先查看下log bin日志和pos值位置
里面有个File和Position，分别是log_file和log_pos的值，一会儿要填
&lt;code>mysql&amp;gt; show master status;&lt;/code>&lt;/p>
&lt;p>master配置如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">mysql&amp;gt; GRANT REPLICATION SLAVE ON *.* TO &amp;#39;replication&amp;#39;@&amp;#39;192.168.1.%&amp;#39; IDENTIFIED BY &amp;#39;replication&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; flush privileges;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; change master to
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_host=&amp;#39;192.168.1.212&amp;#39;, # 此处输入slave的ip地址
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_user=&amp;#39;replication&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_password=&amp;#39;replication&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_log_file=&amp;#39;mysql-bin.000001&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_log_pos=120; #对端状态显示的值
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; start slave; #启动同步
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>backup配置如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">mysql&amp;gt; GRANT REPLICATION SLAVE ON *.* TO &amp;#39;replication&amp;#39;@&amp;#39;192.168.1.%&amp;#39; IDENTIFIED BY &amp;#39;replication&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; flush privileges;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; change master to
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_host=&amp;#39;192.168.1.211&amp;#39;, # 此处输入master的ip地址
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_user=&amp;#39;replication&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_password=&amp;#39;replication&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_log_file=&amp;#39;mysql-bin.000001&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -&amp;gt; master_log_pos=120;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql&amp;gt; start slave;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>MySQL双击热备安装完成&lt;/p>
&lt;h2 id="测试">测试
&lt;/h2>&lt;p>在一台机器上建立一个数据库，创建一个表，在另一台机器上查询是有结果的，说明安装成功。&lt;/p></description></item><item><title>Hadoop HA安装一：在Linux中安装和配置ntp，ssh和jdk</title><link>https://davidham3.github.io/blog/p/hadoop-ha%E5%AE%89%E8%A3%85%E4%B8%80%E5%9C%A8linux%E4%B8%AD%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEntpssh%E5%92%8Cjdk/</link><pubDate>Mon, 21 Aug 2017 16:13:25 +0000</pubDate><guid>https://davidham3.github.io/blog/p/hadoop-ha%E5%AE%89%E8%A3%85%E4%B8%80%E5%9C%A8linux%E4%B8%AD%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEntpssh%E5%92%8Cjdk/</guid><description>&lt;p>Hadoop HA安装一：安装和配置ntp，ssh和jdk&lt;/p>
&lt;p>记录一下安装5节点的高可用Hadoop集群的安装过程。High availability表示高可用，在Hadoop集群中，表示两个主节点。HDFS中是两个Namenode，Yarn中是两个ResourceManager。本教程中的Hadoop和HBase均为HA，MySQL为双机热备。&lt;/p>
&lt;p>操作系统：CentOS 7.&lt;/p>
&lt;p>软件服务如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>软件&lt;/th>
&lt;th>版本&lt;/th>
&lt;th>路径&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>JDK&lt;/td>
&lt;td>1.7.80&lt;/td>
&lt;td>/usr/local/jdk1.7.0_80&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MySQL&lt;/td>
&lt;td>5.6.37&lt;/td>
&lt;td>/usr/local/mysql&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zookeeper&lt;/td>
&lt;td>3.4.6&lt;/td>
&lt;td>/usr/local/zookeeper-3.4.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Kafka&lt;/td>
&lt;td>0.8.2.1&lt;/td>
&lt;td>/usr/local/kafka_2.10.-0.8.2.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Hadoop&lt;/td>
&lt;td>2.6.5&lt;/td>
&lt;td>/usr/local/hadoop-2.6.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>HBase&lt;/td>
&lt;td>1.2.6&lt;/td>
&lt;td>/usr/local/hbase-1.2.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Hive&lt;/td>
&lt;td>1.1.0&lt;/td>
&lt;td>/usr/local/apache-hive-1.1.0-bin&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MySQL JDBC&lt;/td>
&lt;td>5.1.43&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Scala&lt;/td>
&lt;td>2.10.6&lt;/td>
&lt;td>/usr/local/scala-2.10.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Spark&lt;/td>
&lt;td>1.6.3&lt;/td>
&lt;td>/usr/local/spark-1.6.3-bin-hadoop2.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storm&lt;/td>
&lt;td>1.1.1&lt;/td>
&lt;td>/usr/local/apache-storm-1.1.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sqoop&lt;/td>
&lt;td>1.4.6&lt;/td>
&lt;td>/usr/local/sqoop-1.4.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Pig&lt;/td>
&lt;td>0.16.0&lt;/td>
&lt;td>/usr/local/pig-0.16.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>各节点搭载的服务为：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Hostname&lt;/th>
&lt;th>Services&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>cluster1&lt;/td>
&lt;td>NameNode, DataNode, ZKFC, ResourceManager, NodeManager, HMaster, HRegionServer, Master, Worker, MySQL&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cluster2&lt;/td>
&lt;td>QuorumPeerMain, NameNode, DataNode, ZKFC, ResourceManager, NodeManager, HMaster, HRegionServer, Worker, MySQL&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cluster3&lt;/td>
&lt;td>QuorumPeerMain, DataNode, NodeManager, HRegionServer, Worker, Kafka, nimbus, core, logviewer&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cluster4&lt;/td>
&lt;td>QuorumPeerMain, DataNode, NodeManager, HRegionServer, Worker, Kafka, Supervisor, logviewer&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cluster5&lt;/td>
&lt;td>DataNode, NodeManager, HRegionServer, Worker, Kafka, Supervisor, logviewer&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>本系列教程中，命令以#开头的是需要使用root用户执行，$开头的使用普通用户（一般为hadoop用户）。而且本教程的操作系统是CentOS7，有些配置文件内的内容可能与Ubuntu等系统不符。&lt;/strong>&lt;/p>
&lt;h1 id="关闭防火墙和selinux">关闭防火墙和Selinux
&lt;/h1>&lt;p>// 关闭防火墙和selinux
&lt;code># systemctl stop firewalld.service&lt;/code>&lt;/p>
&lt;p>// 禁止firewall 开机启动
&lt;code># systemctl disable firewalld.service&lt;/code>&lt;/p>
&lt;p>// 开机关闭Selinux，编辑Selinux配置文件
&lt;code># vi /etc/selinux/config&lt;/code>
将SELINUX设置为disabled
如下:
&lt;code>SELINUX=disabled&lt;/code>
&lt;strong>千万别把SELINUXTYPE改了！&lt;/strong>&lt;/p>
&lt;p>// 重启
&lt;code># reboot&lt;/code>&lt;/p>
&lt;p>// 重启机器后root用户查看Selinux状态
&lt;code># getenforce&lt;/code>&lt;/p>
&lt;h1 id="修改hosts文件">修改hosts文件
&lt;/h1>&lt;p>假设5台机器的IP地址分别为192.168.1.211-192.168.1.215
每台机器都要做如下修改：
// 修改hosts
&lt;code># vi /etc/hosts&lt;/code>
// 在最下面添加以下几行内容&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">192.168.1.211 cluster1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">192.168.1.212 cluster2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">192.168.1.213 cluster3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">192.168.1.214 cluster4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">192.168.1.215 cluster5
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>修改成这个样子后，对于这台机器来说，cluster1就代表了192.168.1.211，其他的也同理。&lt;/p>
&lt;h1 id="ntp的安装与配置">ntp的安装与配置
&lt;/h1>&lt;p>一个集群内需要有一个机器运行ntp server，其他机器用ntpdate向它同步时间。Hbase和Spark都要求时间是严格同步的，所以ntp是必需的。
我们将ntp server设置在cluster1上，所以只在cluster1上面安装ntpserver，在其他机器上安装ntpdate。&lt;/p>
&lt;p>ubuntu下使用如下命令安装&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># apt-get install ntp
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># apt-get install ntpdate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>CentOS使用&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># yum install ntp
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># yum install ntpdate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置时间服务器：&lt;/p>
&lt;p>// cluster1上执行以下操作
&lt;code># vi /etc/ntp.conf&lt;/code>&lt;/p>
&lt;p>注释掉以下4行，也就是在这4行前面加#&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">server 0.centos.pool.ntp.org iburst
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server 1.centos.pool.ntp.org iburst
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server 2.centos.pool.ntp.org iburst
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server 3.centos.pool.ntp.org iburst
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>最下面加入以下内容，192.168.1.1和255.255.255.0分别为网关和掩码，127.127.1.0表示以本机时间为标准。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">restrict default ignore
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">restrict 192.168.1.1 mask 255.255.255.0 nomodify notrap
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server 127.127.1.0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>保存后ubuntu使用&lt;code># /etc/init.d/ntp restart&lt;/code>重启ntp服务，CentOS使用&lt;code># service ntpd restart&lt;/code>
除了搭载ntp server的主机，其他所有机器，设定每天00:00向ntp server同步时间，并写入日志
&lt;code># crontab –e&lt;/code>
添加以下内容&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">0 0 * * * /usr/sbin/ntpdate cluster1&amp;gt;&amp;gt; /home/hadoop/ntpd.log
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这样就完成了ntp的配置&lt;/p>
&lt;p>// 手动同步时间，需要在每台机器上（除ntp server），使用&lt;code>ntpdate cluster1&lt;/code>同步时间
&lt;code># ntpdate cluster1&lt;/code>&lt;/p>
&lt;h1 id="新建hadoop用户">新建hadoop用户
&lt;/h1>&lt;p>每台机器上都要新建hadoop用户，这个用户专门用来维护集群，因为实际中使用root用户的机会很少，而且不安全。
// 新建hadoop组
&lt;code># groupadd hadoop&lt;/code>&lt;/p>
&lt;p>// 新建hadoop用户
&lt;code># useradd -s /bin/bash -g hadoop -d /home/hadoop -m hadoop&lt;/code>&lt;/p>
&lt;p>// 修改hadoop这个用户的密码
&lt;code># passwd hadoop&lt;/code>&lt;/p>
&lt;h1 id="ssh密钥的生成与分发">ssh密钥的生成与分发
&lt;/h1>&lt;p>ssh是Linux自带的服务，不需要安装。这里的目的是让节点间实现无密码登陆。其实就是当前机器生成密钥，然后用&lt;code>ssh-copy-id&lt;/code>复制到其他机器上，这样这台机器就可以无密码直接登陆那台机器了。Hadoop主节点需要能无密码连接到其他的机器上。&lt;/p>
&lt;p>在cluster1上，使用hadoop用户&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">// 使用hadoop用户
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># su hadoop
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 切到home目录
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cd ~/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 生成密钥
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ssh-keygen -t rsa
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 一路回车
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">//复制密钥
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh-copy-id cluster1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">yes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">输入cluster的密码
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh-copy-id cluster2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">同上
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh-copy-id cluster3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">同上
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh-copy-id cluster4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">同上
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh-copy-id cluster5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">同上
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 然后测试能否无密码登陆
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh cluster1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh cluster2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh cluster3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh cluster4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ssh cluster5
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>查看登陆时是否有密码，若无密码，则配置成功。
以上步骤需要在cluster2上也执行一遍，为了让cluster2也可以无密码登陆到其他机器上，因为cluster2也是主节点。&lt;/p>
&lt;h1 id="jdk的安装与配置">jdk的安装与配置
&lt;/h1>&lt;p>安装hadoop集群，jdk是必须要装的，1.7和1.8都可以，不过从Hadoop3开始，好像只支持1.8+了，但是换成1.9和1.10会出问题，所以推荐用1.8，我这里用的是1.7。&lt;/p>
&lt;p>将下载好后的jdk解压到/usr/local/下
&lt;code># vi /etc/profile&lt;/code>
将下面4行添加到环境变量中&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">JAVA_HOME&lt;/span>&lt;span class="o">=/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">local&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">jdk1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="mf">7.0&lt;/span>&lt;span class="n">_80&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">JRE_HOME&lt;/span>&lt;span class="o">=/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">local&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">jdk1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="mf">7.0&lt;/span>&lt;span class="n">_80&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">jre&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">CLASSPATH&lt;/span>&lt;span class="o">=.&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">JAVA&lt;/span>\&lt;span class="n">_HOME&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">lib&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">JRE_HOME&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">lib&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">CLASSPATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">export&lt;/span> &lt;span class="n">PATH&lt;/span>&lt;span class="o">=$&lt;/span>&lt;span class="n">JAVA_HOME&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bin&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">JRE&lt;/span>\&lt;span class="n">_HOME&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bin&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">JAVA_HOME&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用&lt;code># source /etc/profile&lt;/code>刷新环境变量
使用&lt;code># java -version&lt;/code>查看java版本验证是否安装成功，如果能看到Java的版本，说明安装成功，没有问题。&lt;/p></description></item></channel></rss>